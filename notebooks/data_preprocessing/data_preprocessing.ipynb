{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9c02fc0-a5fa-4082-948c-e48013cef136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 17:01:20,551] INFO: ✔ Loaded \"ga_sessions\" from PKL, shape=(1860042, 18)\n",
      "[2025-04-27 17:03:11,034] INFO: ✔ Loaded \"ga_hits\" from PKL, shape=(15726470, 11)\n",
      "[2025-04-27 17:03:11,049] INFO: --- Inspecting \"Sessions\" ---\n",
      "[2025-04-27 17:03:11,052] INFO: Shape: (1860042, 18)\n",
      "[2025-04-27 17:03:11,055] INFO: Dtypes:\n",
      "[2025-04-27 17:03:11,068] INFO:     session_id: object\n",
      "[2025-04-27 17:03:11,068] INFO:     client_id: object\n",
      "[2025-04-27 17:03:11,069] INFO:     visit_date: object\n",
      "[2025-04-27 17:03:11,070] INFO:     visit_time: object\n",
      "[2025-04-27 17:03:11,071] INFO:     visit_number: int64\n",
      "[2025-04-27 17:03:11,072] INFO:     utm_source: object\n",
      "[2025-04-27 17:03:11,072] INFO:     utm_medium: object\n",
      "[2025-04-27 17:03:11,072] INFO:     utm_campaign: object\n",
      "[2025-04-27 17:03:11,072] INFO:     utm_adcontent: object\n",
      "[2025-04-27 17:03:11,073] INFO:     utm_keyword: object\n",
      "[2025-04-27 17:03:11,073] INFO:     device_category: object\n",
      "[2025-04-27 17:03:11,073] INFO:     device_os: object\n",
      "[2025-04-27 17:03:11,074] INFO:     device_brand: object\n",
      "[2025-04-27 17:03:11,074] INFO:     device_model: object\n",
      "[2025-04-27 17:03:11,074] INFO:     device_screen_resolution: object\n",
      "[2025-04-27 17:03:11,075] INFO:     device_browser: object\n",
      "[2025-04-27 17:03:11,076] INFO:     geo_country: object\n",
      "[2025-04-27 17:03:11,076] INFO:     geo_city: object\n",
      "[2025-04-27 17:03:13,832] INFO: Missing values:\n",
      "[2025-04-27 17:03:13,838] INFO:     utm_source: 97\n",
      "[2025-04-27 17:03:13,838] INFO:     utm_campaign: 219603\n",
      "[2025-04-27 17:03:13,838] INFO:     utm_adcontent: 335615\n",
      "[2025-04-27 17:03:13,839] INFO:     utm_keyword: 1082061\n",
      "[2025-04-27 17:03:13,839] INFO:     device_os: 1070138\n",
      "[2025-04-27 17:03:13,839] INFO:     device_brand: 118678\n",
      "[2025-04-27 17:03:13,839] INFO:     device_model: 1843704\n",
      "[2025-04-27 17:03:16,013] INFO: Duplicate rows: 0\n",
      "[2025-04-27 17:03:16,015] INFO: --- Inspecting \"Hits\" ---\n",
      "[2025-04-27 17:03:16,015] INFO: Shape: (15726470, 11)\n",
      "[2025-04-27 17:03:16,015] INFO: Dtypes:\n",
      "[2025-04-27 17:03:16,016] INFO:     session_id: object\n",
      "[2025-04-27 17:03:16,016] INFO:     hit_date: object\n",
      "[2025-04-27 17:03:16,016] INFO:     hit_time: float64\n",
      "[2025-04-27 17:03:16,017] INFO:     hit_number: int64\n",
      "[2025-04-27 17:03:16,017] INFO:     hit_type: object\n",
      "[2025-04-27 17:03:16,017] INFO:     hit_referer: object\n",
      "[2025-04-27 17:03:16,017] INFO:     hit_page_path: object\n",
      "[2025-04-27 17:03:16,017] INFO:     event_category: object\n",
      "[2025-04-27 17:03:16,018] INFO:     event_action: object\n",
      "[2025-04-27 17:03:16,018] INFO:     event_label: object\n",
      "[2025-04-27 17:03:16,018] INFO:     event_value: object\n",
      "[2025-04-27 17:03:22,353] INFO: Missing values:\n",
      "[2025-04-27 17:03:22,355] INFO:     hit_time: 9160322\n",
      "[2025-04-27 17:03:22,355] INFO:     hit_referer: 6274804\n",
      "[2025-04-27 17:03:22,356] INFO:     event_label: 3760184\n",
      "[2025-04-27 17:03:22,356] INFO:     event_value: 15726470\n",
      "[2025-04-27 17:03:40,150] INFO: Duplicate rows: 0\n",
      "[2025-04-27 17:03:40,154] INFO: → Combining \"visit_date\" + \"visit_time\" → \"visit_ts\"\n",
      "[2025-04-27 17:03:42,982] INFO: → Combining \"hit_date\" + \"hit_time\" → \"hit_ts\"\n",
      "[2025-04-27 17:12:42,358] WARNING:     15144409 invalid \"hit_ts\" generated from hit_date/hit_time\n",
      "[2025-04-27 17:12:52,667] INFO: → Parsing resolution from \"device_screen_resolution\"\n",
      "[2025-04-27 17:13:23,816] INFO:     screen_width NaNs: 8, screen_height NaNs: 8\n",
      "[2025-04-27 17:13:23,824] WARNING:     29 extreme resolutions reset to NaN\n",
      "[2025-04-27 17:13:51,963] INFO:     Dropped 225862 duplicates by ['session_id', 'hit_number']\n",
      "[2025-04-27 17:13:54,942] INFO: → Creating target for actions: ['sub_button_click', 'quiz_show', 'start_chat']\n",
      "[2025-04-27 17:13:55,468] INFO:     Target ratio in hits: {False: 0.9821857955507294, True: 0.017814204449270635}\n",
      "[2025-04-27 17:14:03,439] INFO:     \"utm_source\" → category (293 unique)\n",
      "[2025-04-27 17:14:03,594] INFO:     \"utm_medium\" → category (56 unique)\n",
      "[2025-04-27 17:14:03,688] INFO:     \"utm_campaign\" → category (412 unique)\n",
      "[2025-04-27 17:14:03,770] INFO:     \"utm_adcontent\" → category (286 unique)\n",
      "[2025-04-27 17:14:03,859] INFO:     \"utm_keyword\" → category (1219 unique)\n",
      "[2025-04-27 17:14:03,990] INFO:     \"device_category\" → category (3 unique)\n",
      "[2025-04-27 17:14:04,105] INFO:     \"device_os\" → category (13 unique)\n",
      "[2025-04-27 17:14:04,235] INFO:     \"device_brand\" → category (206 unique)\n",
      "[2025-04-27 17:14:04,297] INFO:     \"device_model\" → category (104 unique)\n",
      "[2025-04-27 17:14:04,431] INFO:     \"device_browser\" → category (57 unique)\n",
      "[2025-04-27 17:14:04,540] INFO:     \"geo_country\" → category (166 unique)\n",
      "[2025-04-27 17:14:04,677] INFO:     \"geo_city\" → category (2548 unique)\n",
      "[2025-04-27 17:14:19,214] INFO:     \"session_id\" → category (1734610 unique)\n",
      "[2025-04-27 17:14:20,380] INFO:     \"hit_type\" → category (1 unique)\n",
      "[2025-04-27 17:14:21,008] INFO:     \"hit_referer\" → category (37873 unique)\n",
      "[2025-04-27 17:14:30,422] INFO:     \"hit_page_path\" → category (342715 unique)\n",
      "[2025-04-27 17:14:31,823] INFO:     \"event_category\" → category (52 unique)\n",
      "[2025-04-27 17:14:33,432] INFO:     \"event_action\" → category (230 unique)\n",
      "[2025-04-27 17:14:34,067] INFO:     \"event_label\" → category (39825 unique)\n",
      "[2025-04-27 17:14:36,849] INFO:     \"event_value\" → category (0 unique)\n",
      "[2025-04-27 17:14:38,402] INFO: ✔ Saved processed data: /Users/aleksey.sushchikh/Desktop/GitHub/MIFIHackatonSberAutoSubscriptionAnalysis/data/processed_data/processed_sessions.pkl, /Users/aleksey.sushchikh/Desktop/GitHub/MIFIHackatonSberAutoSubscriptionAnalysis/data/processed_data/processed_hits.pkl\n",
      "[2025-04-27 17:14:38,403] INFO: ✅ Preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_logger():\n",
    "    \"\"\"Настройка логгера для вывода информации о ходе обработки.\"\"\"\n",
    "    logger = logging.getLogger('data_preprocessing')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.handlers.clear()\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    fmt = logging.Formatter('[%(asctime)s] %(levelname)s: %(message)s')\n",
    "    ch.setFormatter(fmt)\n",
    "    logger.addHandler(ch)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def find_project_root(start_path: Path = None, marker: str = 'raw_data'):\n",
    "    \"\"\"\n",
    "    Поднимаемся вверх от start_path (или cwd), пока не найдём папку data/raw_data.\n",
    "    \"\"\"\n",
    "    p = Path(start_path or Path.cwd()).resolve()\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / 'data' / marker).is_dir():\n",
    "            return parent\n",
    "    raise FileNotFoundError('Не удалось найти корень проекта с папкой data/raw_data')\n",
    "\n",
    "\n",
    "def setup_paths(base_dir: Path = None):\n",
    "    \"\"\"Определяем пути raw/processed относительно корня проекта.\"\"\"\n",
    "    project_root = find_project_root(base_dir)\n",
    "    raw = project_root / 'data' / 'raw_data'\n",
    "    processed = project_root / 'data' / 'processed_data'\n",
    "    processed.mkdir(parents=True, exist_ok=True)\n",
    "    return {'raw': raw, 'processed': processed}\n",
    "\n",
    "\n",
    "def load_data(paths: dict, logger: logging.Logger):\n",
    "    \"\"\"\n",
    "    Читаем ga_sessions и ga_hits.\n",
    "    Сначала пытаемся загрузить .pkl, если нет — fallback на .csv.\n",
    "    \"\"\"\n",
    "    def _load(name):\n",
    "        pkl = paths['raw'] / f'{name}.pkl'\n",
    "        csv = paths['raw'] / f'{name}.csv'\n",
    "        if pkl.exists():\n",
    "            df = pd.read_pickle(pkl)\n",
    "            logger.info(f'✔ Loaded \"{name}\" from PKL, shape={df.shape}')\n",
    "        elif csv.exists():\n",
    "            df = pd.read_csv(csv)\n",
    "            logger.info(f'✔ Loaded \"{name}\" from CSV, shape={df.shape}')\n",
    "        else:\n",
    "            msg = f'\"{name}\" not found in {pkl} or {csv}'\n",
    "            logger.error(msg)\n",
    "            raise FileNotFoundError(msg)\n",
    "        return df\n",
    "\n",
    "    sessions = _load('ga_sessions')\n",
    "    hits = _load('ga_hits')\n",
    "    return sessions, hits\n",
    "\n",
    "\n",
    "def inspect_df(df: pd.DataFrame, name: str, logger: logging.Logger):\n",
    "    \"\"\"Печать базовой статистики: форма, типы, пропуски, дубликаты.\"\"\"\n",
    "    logger.info(f'--- Inspecting \"{name}\" ---')\n",
    "    logger.info(f'Shape: {df.shape}')\n",
    "    logger.info('Dtypes:')\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        logger.info(f'    {col}: {dtype}')\n",
    "    nulls = df.isnull().sum()\n",
    "    if nulls.sum():\n",
    "        logger.info('Missing values:')\n",
    "        for col, cnt in nulls[nulls > 0].items():\n",
    "            logger.info(f'    {col}: {cnt}')\n",
    "    else:\n",
    "        logger.info('No missing values.')\n",
    "    dup = df.duplicated().sum()\n",
    "    logger.info(f'Duplicate rows: {dup}')\n",
    "    if dup:\n",
    "        logger.info('Example duplicates:')\n",
    "        logger.info(df[df.duplicated()].head(3).to_string())\n",
    "\n",
    "\n",
    "def process_datetime(df: pd.DataFrame, date_col: str, time_col: str, new_col: str, logger: logging.Logger):\n",
    "    \"\"\"Объединяем дату и время в Timestamp, логируем ошибки парсинга.\"\"\"\n",
    "    logger.info(f'→ Combining \"{date_col}\" + \"{time_col}\" → \"{new_col}\"')\n",
    "    df[new_col] = pd.to_datetime(\n",
    "        df[date_col].astype(str).str.strip() + ' ' + df[time_col].astype(str).str.strip(),\n",
    "        errors='coerce'\n",
    "    )\n",
    "    n_bad = df[new_col].isna().sum()\n",
    "    if n_bad:\n",
    "        logger.warning(f'    {n_bad} invalid \"{new_col}\" generated from {date_col}/{time_col}')\n",
    "    df.drop([date_col, time_col], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_resolution(df: pd.DataFrame, col: str, logger: logging.Logger):\n",
    "    \"\"\"\n",
    "    Разбираем строку вида 'WIDTHxHEIGHT' в две числовые колонки,\n",
    "    фильтруем экстремальные значения, логируем статистику.\n",
    "    \"\"\"\n",
    "    logger.info(f'→ Parsing resolution from \"{col}\"')\n",
    "    # Заменяем пустые на '0x0'\n",
    "    df[col] = df[col].fillna('0x0').astype(str)\n",
    "\n",
    "    # Распакуем в две колонки\n",
    "    res = df[col].str.split('x', expand=True)\n",
    "    res.columns = ['w', 'h']\n",
    "    df['screen_width'] = pd.to_numeric(res['w'], errors='coerce')\n",
    "    df['screen_height'] = pd.to_numeric(res['h'], errors='coerce')\n",
    "\n",
    "    # Логируем сколько получилось NaN после парсинга\n",
    "    nan_w = df['screen_width'].isna().sum()\n",
    "    nan_h = df['screen_height'].isna().sum()\n",
    "    logger.info(f'    screen_width NaNs: {nan_w}, screen_height NaNs: {nan_h}')\n",
    "\n",
    "    # Фильтруем экстремумы\n",
    "    mask = (df['screen_width'] > 10000) | (df['screen_height'] > 10000)\n",
    "    if mask.sum():\n",
    "        logger.warning(f'    {mask.sum()} extreme resolutions reset to NaN')\n",
    "        df.loc[mask, ['screen_width', 'screen_height']] = np.nan\n",
    "\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_duplicates(df: pd.DataFrame, subset: list, logger: logging.Logger):\n",
    "    \"\"\"Удаляем дубликаты по ключам subset.\"\"\"\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=subset)\n",
    "    dropped = before - len(df)\n",
    "    if dropped:\n",
    "        logger.info(f'    Dropped {dropped} duplicates by {subset}')\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_dtypes(df: pd.DataFrame, logger: logging.Logger):\n",
    "    \"\"\"Конвертируем object→category, если уникальных значений мало.\"\"\"\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        nunq = df[col].nunique()\n",
    "        if nunq < df.shape[0] * 0.5:\n",
    "            df[col] = df[col].astype('category')\n",
    "            logger.info(f'    \"{col}\" → category ({nunq} unique)')\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_target(sessions: pd.DataFrame, hits: pd.DataFrame, logger: logging.Logger, actions: list = None):\n",
    "    \"\"\"Добавляем бинарный таргет в sessions по событиям hits.\"\"\"\n",
    "    if actions is None:\n",
    "        actions = ['sub_button_click', 'quiz_show', 'start_chat']\n",
    "    logger.info(f'→ Creating target for actions: {actions}')\n",
    "    hits['is_target'] = hits['event_action'].isin(actions)\n",
    "    dist = hits['is_target'].value_counts(normalize=True).to_dict()\n",
    "    logger.info(f'    Target ratio in hits: {dist}')\n",
    "    tgt = (\n",
    "        hits\n",
    "        .groupby('session_id')['is_target']\n",
    "        .any()\n",
    "        .astype(int)\n",
    "        .rename('target')\n",
    "        .reset_index()\n",
    "    )\n",
    "    sessions = sessions.merge(tgt, on='session_id', how='left')\n",
    "    sessions['target'].fillna(0, inplace=True)\n",
    "    return sessions\n",
    "\n",
    "\n",
    "def main():\n",
    "    logger = setup_logger()\n",
    "    paths = setup_paths()\n",
    "    sessions, hits = load_data(paths, logger)\n",
    "\n",
    "    # 1) Предварительный осмотр\n",
    "    inspect_df(sessions, 'Sessions', logger)\n",
    "    inspect_df(hits, 'Hits', logger)\n",
    "\n",
    "    # 2) Обработка дат и времени\n",
    "    sessions = process_datetime(sessions, 'visit_date', 'visit_time', 'visit_ts', logger)\n",
    "    hits = process_datetime(hits, 'hit_date', 'hit_time', 'hit_ts', logger)\n",
    "\n",
    "    # 3) Разбор разрешения экрана\n",
    "    sessions = handle_resolution(sessions, 'device_screen_resolution', logger)\n",
    "\n",
    "    # 4) Удаление дубликатов\n",
    "    sessions = drop_duplicates(sessions, ['session_id'], logger)\n",
    "    hits = drop_duplicates(hits, ['session_id', 'hit_number'], logger)\n",
    "\n",
    "    # 5) Создание целевой переменной\n",
    "    sessions = create_target(sessions, hits, logger)\n",
    "\n",
    "    # 6) Оптимизация типов\n",
    "    sessions = convert_dtypes(sessions, logger)\n",
    "    hits = convert_dtypes(hits, logger)\n",
    "\n",
    "    # 7) Сохранение результатов\n",
    "    out_s = paths['processed'] / 'processed_sessions.pkl'\n",
    "    out_h = paths['processed'] / 'processed_hits.pkl'\n",
    "    sessions.to_pickle(out_s)\n",
    "    hits.to_pickle(out_h)\n",
    "    logger.info(f'✔ Saved processed data: {out_s}, {out_h}')\n",
    "    logger.info('✅ Preprocessing completed.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bee3c-3f10-4ca7-b5fd-c109575f496d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
